{"ast":null,"code":"const openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY\n});\nconst aiModel = \"gpt-4-1106-preview\";\nrequire(\"dotenv\").config();\nconst express = require(\"express\");\nconst cors = require(\"cors\");\nconst OpenAI = require(\"openai\");\nconst app = express();\nconst PORT = 3001;\n\n// Enable CORS for all routes\napp.use(cors());\n\n// SSE Endpoint\napp.get(\"/recipeStream\", (req, res) => {\n  const ingredients = req.query.ingredients;\n  const mealType = req.query.mealType;\n  const cuisine = req.query.cuisine;\n  const cookingTime = req.query.cookingTime;\n  const complexity = req.query.complexity;\n  console.log(req.query);\n  res.setHeader(\"Content-Type\", \"text/event-stream\");\n  res.setHeader(\"Cache-Control\", \"no-cache\");\n  res.setHeader(\"Connection\", \"keep-alive\");\n\n  // Function to send messages\n  const sendEvent = chunk => {\n    let chunkResponse;\n    if (chunk.choices[0].finish_reason === \"stop\") {\n      res.write(`data: ${JSON.stringify({\n        action: \"close\"\n      })}\\n\\n`);\n    } else {\n      if (chunk.choices[0].delta.role && chunk.choices[0].delta.role === \"assistant\") {\n        chunkResponse = {\n          action: \"start\"\n        };\n      } else {\n        chunkResponse = {\n          action: \"chunk\",\n          chunk: chunk.choices[0].delta.content\n        };\n      }\n      res.write(`data: ${JSON.stringify(chunkResponse)}\\n\\n`);\n    }\n  };\n  const prompt = [];\n  prompt.push(\"Generate a recipe that incorporates the following details:\");\n  prompt.push(`[Ingredients: ${ingredients}]`);\n  prompt.push(`[Meal Type: ${mealType}]`);\n  prompt.push(`[Cuisine Preference: ${cuisine}]`);\n  prompt.push(`[Cooking Time: ${cookingTime}]`);\n  prompt.push(`[Complexity: ${complexity}]`);\n  prompt.push(\"Please provide a detailed recipe, including the following sections:\");\n  prompt.push(\"- A recipe name in the local language based on the cuisine preference.\");\n  prompt.push(\"- A list of ingredients with their exact measurements.\");\n  prompt.push(\"- A detailed set of instructions broken into numbered steps. Each step should be clear, concise, and logically ordered.\");\n  prompt.push(\"- Optional: If the recipe has a suggested garnish, side dish, or variation, please include it at the end.\");\n  prompt.push(\"Please format the instructions in a way that makes it easy for a user to follow. Separate each instruction step with a blank line to improve readability.\");\n  prompt.push(\"Ensure that the recipe highlights the fresh and vibrant flavors of the ingredients.\");\n  prompt.push(\"Only use the ingredients provided in the list, and be sure to stay within the specified cooking time and complexity.\");\n  const messages = [{\n    role: \"system\",\n    content: prompt.join(\" \")\n  }];\n  fetchOpenAICompletionsStream(messages, sendEvent);\n\n  // Clear interval and close connection on client disconnect\n  req.on(\"close\", () => {\n    res.end();\n  });\n});\nasync function fetchOpenAICompletionsStream(messages, callback) {\n  const openai = new OpenAI({\n    apiKey: process.env.OPENAI_API_KEY\n  });\n  const aiModel = \"gpt-4-1106-preview\";\n  try {\n    const completion = await openai.chat.completions.create({\n      model: aiModel,\n      messages: messages,\n      temperature: 1,\n      stream: true\n    });\n    for await (const chunk of completion) {\n      callback(chunk);\n    }\n  } catch (error) {\n    console.error(\"Error fetching data from OpenAI API:\", error);\n    throw new Error(\"Error fetching data from OpenAI API.\");\n  }\n}\napp.listen(PORT, () => {\n  console.log(`Server running on port ${PORT}`);\n});","map":{"version":3,"names":["openai","OpenAI","apiKey","process","env","OPENAI_API_KEY","aiModel","require","config","express","cors","app","PORT","use","get","req","res","ingredients","query","mealType","cuisine","cookingTime","complexity","console","log","setHeader","sendEvent","chunk","chunkResponse","choices","finish_reason","write","JSON","stringify","action","delta","role","content","prompt","push","messages","join","fetchOpenAICompletionsStream","on","end","callback","completion","chat","completions","create","model","temperature","stream","error","Error","listen"],"sources":["/Users/hareemsalman/Downloads/React Recipe Generator/client/recipe-gen/src/App.js"],"sourcesContent":["const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });\nconst aiModel = \"gpt-4-1106-preview\";\n\nrequire(\"dotenv\").config();\n\nconst express = require(\"express\");\nconst cors = require(\"cors\");\nconst OpenAI = require(\"openai\");\n\nconst app = express();\nconst PORT = 3001;\n\n// Enable CORS for all routes\napp.use(cors());\n\n\n// SSE Endpoint\napp.get(\"/recipeStream\", (req, res) => {\n  const ingredients = req.query.ingredients;\n  const mealType = req.query.mealType;\n  const cuisine = req.query.cuisine;\n  const cookingTime = req.query.cookingTime;\n  const complexity = req.query.complexity;\n\n  console.log(req.query)\n\n  res.setHeader(\"Content-Type\", \"text/event-stream\");\n  res.setHeader(\"Cache-Control\", \"no-cache\");\n  res.setHeader(\"Connection\", \"keep-alive\");\n\n  // Function to send messages\n  const sendEvent = (chunk) => {\n    let chunkResponse;\n    if (chunk.choices[0].finish_reason === \"stop\") {\n      res.write(`data: ${JSON.stringify({ action: \"close\" })}\\n\\n`);\n    } else {\n      if (\n        chunk.choices[0].delta.role &&\n        chunk.choices[0].delta.role === \"assistant\"\n      ) {\n        chunkResponse = {\n          action: \"start\",\n        };\n      } else {\n        chunkResponse = {\n          action: \"chunk\",\n          chunk: chunk.choices[0].delta.content,\n        };\n      }\n      res.write(`data: ${JSON.stringify(chunkResponse)}\\n\\n`);\n    }\n  };\n\n  const prompt = [];\n    prompt.push(\"Generate a recipe that incorporates the following details:\");\n    prompt.push(`[Ingredients: ${ingredients}]`);\n    prompt.push(`[Meal Type: ${mealType}]`);\n    prompt.push(`[Cuisine Preference: ${cuisine}]`);\n    prompt.push(`[Cooking Time: ${cookingTime}]`);\n    prompt.push(`[Complexity: ${complexity}]`);\n    prompt.push(\"Please provide a detailed recipe, including the following sections:\");\n\n    prompt.push(\"- A recipe name in the local language based on the cuisine preference.\");\n    prompt.push(\"- A list of ingredients with their exact measurements.\");\n    prompt.push(\"- A detailed set of instructions broken into numbered steps. Each step should be clear, concise, and logically ordered.\");\n    prompt.push(\"- Optional: If the recipe has a suggested garnish, side dish, or variation, please include it at the end.\");\n    prompt.push(\"Please format the instructions in a way that makes it easy for a user to follow. Separate each instruction step with a blank line to improve readability.\");\n    prompt.push(\"Ensure that the recipe highlights the fresh and vibrant flavors of the ingredients.\");\n    prompt.push(\"Only use the ingredients provided in the list, and be sure to stay within the specified cooking time and complexity.\");\n\n\n  const messages = [\n    {\n      role: \"system\",\n      content: prompt.join(\" \"),\n    },\n  ];\n  fetchOpenAICompletionsStream(messages, sendEvent);\n\n  // Clear interval and close connection on client disconnect\n  req.on(\"close\", () => {\n    res.end();\n  });\n});\n\nasync function fetchOpenAICompletionsStream(messages, callback) {\n    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });\n\n    const aiModel = \"gpt-4-1106-preview\";\n\n  try {\n    const completion = await openai.chat.completions.create({\n      model: aiModel,\n      messages: messages,\n      temperature: 1,\n      stream: true,\n    });\n\n    for await (const chunk of completion) {\n      callback(chunk);\n    }\n  } catch (error) {\n    console.error(\"Error fetching data from OpenAI API:\", error);\n    throw new Error(\"Error fetching data from OpenAI API.\");\n  }\n}\n\napp.listen(PORT, () => {\n  console.log(`Server running on port ${PORT}`);\n});"],"mappings":"AAAA,MAAMA,MAAM,GAAG,IAAIC,MAAM,CAAC;EAAEC,MAAM,EAAEC,OAAO,CAACC,GAAG,CAACC;AAAe,CAAC,CAAC;AACjE,MAAMC,OAAO,GAAG,oBAAoB;AAEpCC,OAAO,CAAC,QAAQ,CAAC,CAACC,MAAM,CAAC,CAAC;AAE1B,MAAMC,OAAO,GAAGF,OAAO,CAAC,SAAS,CAAC;AAClC,MAAMG,IAAI,GAAGH,OAAO,CAAC,MAAM,CAAC;AAC5B,MAAMN,MAAM,GAAGM,OAAO,CAAC,QAAQ,CAAC;AAEhC,MAAMI,GAAG,GAAGF,OAAO,CAAC,CAAC;AACrB,MAAMG,IAAI,GAAG,IAAI;;AAEjB;AACAD,GAAG,CAACE,GAAG,CAACH,IAAI,CAAC,CAAC,CAAC;;AAGf;AACAC,GAAG,CAACG,GAAG,CAAC,eAAe,EAAE,CAACC,GAAG,EAAEC,GAAG,KAAK;EACrC,MAAMC,WAAW,GAAGF,GAAG,CAACG,KAAK,CAACD,WAAW;EACzC,MAAME,QAAQ,GAAGJ,GAAG,CAACG,KAAK,CAACC,QAAQ;EACnC,MAAMC,OAAO,GAAGL,GAAG,CAACG,KAAK,CAACE,OAAO;EACjC,MAAMC,WAAW,GAAGN,GAAG,CAACG,KAAK,CAACG,WAAW;EACzC,MAAMC,UAAU,GAAGP,GAAG,CAACG,KAAK,CAACI,UAAU;EAEvCC,OAAO,CAACC,GAAG,CAACT,GAAG,CAACG,KAAK,CAAC;EAEtBF,GAAG,CAACS,SAAS,CAAC,cAAc,EAAE,mBAAmB,CAAC;EAClDT,GAAG,CAACS,SAAS,CAAC,eAAe,EAAE,UAAU,CAAC;EAC1CT,GAAG,CAACS,SAAS,CAAC,YAAY,EAAE,YAAY,CAAC;;EAEzC;EACA,MAAMC,SAAS,GAAIC,KAAK,IAAK;IAC3B,IAAIC,aAAa;IACjB,IAAID,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAACC,aAAa,KAAK,MAAM,EAAE;MAC7Cd,GAAG,CAACe,KAAK,CAAC,SAASC,IAAI,CAACC,SAAS,CAAC;QAAEC,MAAM,EAAE;MAAQ,CAAC,CAAC,MAAM,CAAC;IAC/D,CAAC,MAAM;MACL,IACEP,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAACM,KAAK,CAACC,IAAI,IAC3BT,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAACM,KAAK,CAACC,IAAI,KAAK,WAAW,EAC3C;QACAR,aAAa,GAAG;UACdM,MAAM,EAAE;QACV,CAAC;MACH,CAAC,MAAM;QACLN,aAAa,GAAG;UACdM,MAAM,EAAE,OAAO;UACfP,KAAK,EAAEA,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAACM,KAAK,CAACE;QAChC,CAAC;MACH;MACArB,GAAG,CAACe,KAAK,CAAC,SAASC,IAAI,CAACC,SAAS,CAACL,aAAa,CAAC,MAAM,CAAC;IACzD;EACF,CAAC;EAED,MAAMU,MAAM,GAAG,EAAE;EACfA,MAAM,CAACC,IAAI,CAAC,4DAA4D,CAAC;EACzED,MAAM,CAACC,IAAI,CAAC,iBAAiBtB,WAAW,GAAG,CAAC;EAC5CqB,MAAM,CAACC,IAAI,CAAC,eAAepB,QAAQ,GAAG,CAAC;EACvCmB,MAAM,CAACC,IAAI,CAAC,wBAAwBnB,OAAO,GAAG,CAAC;EAC/CkB,MAAM,CAACC,IAAI,CAAC,kBAAkBlB,WAAW,GAAG,CAAC;EAC7CiB,MAAM,CAACC,IAAI,CAAC,gBAAgBjB,UAAU,GAAG,CAAC;EAC1CgB,MAAM,CAACC,IAAI,CAAC,qEAAqE,CAAC;EAElFD,MAAM,CAACC,IAAI,CAAC,wEAAwE,CAAC;EACrFD,MAAM,CAACC,IAAI,CAAC,wDAAwD,CAAC;EACrED,MAAM,CAACC,IAAI,CAAC,yHAAyH,CAAC;EACtID,MAAM,CAACC,IAAI,CAAC,2GAA2G,CAAC;EACxHD,MAAM,CAACC,IAAI,CAAC,2JAA2J,CAAC;EACxKD,MAAM,CAACC,IAAI,CAAC,qFAAqF,CAAC;EAClGD,MAAM,CAACC,IAAI,CAAC,sHAAsH,CAAC;EAGrI,MAAMC,QAAQ,GAAG,CACf;IACEJ,IAAI,EAAE,QAAQ;IACdC,OAAO,EAAEC,MAAM,CAACG,IAAI,CAAC,GAAG;EAC1B,CAAC,CACF;EACDC,4BAA4B,CAACF,QAAQ,EAAEd,SAAS,CAAC;;EAEjD;EACAX,GAAG,CAAC4B,EAAE,CAAC,OAAO,EAAE,MAAM;IACpB3B,GAAG,CAAC4B,GAAG,CAAC,CAAC;EACX,CAAC,CAAC;AACJ,CAAC,CAAC;AAEF,eAAeF,4BAA4BA,CAACF,QAAQ,EAAEK,QAAQ,EAAE;EAC5D,MAAM7C,MAAM,GAAG,IAAIC,MAAM,CAAC;IAAEC,MAAM,EAAEC,OAAO,CAACC,GAAG,CAACC;EAAe,CAAC,CAAC;EAEjE,MAAMC,OAAO,GAAG,oBAAoB;EAEtC,IAAI;IACF,MAAMwC,UAAU,GAAG,MAAM9C,MAAM,CAAC+C,IAAI,CAACC,WAAW,CAACC,MAAM,CAAC;MACtDC,KAAK,EAAE5C,OAAO;MACdkC,QAAQ,EAAEA,QAAQ;MAClBW,WAAW,EAAE,CAAC;MACdC,MAAM,EAAE;IACV,CAAC,CAAC;IAEF,WAAW,MAAMzB,KAAK,IAAImB,UAAU,EAAE;MACpCD,QAAQ,CAAClB,KAAK,CAAC;IACjB;EACF,CAAC,CAAC,OAAO0B,KAAK,EAAE;IACd9B,OAAO,CAAC8B,KAAK,CAAC,sCAAsC,EAAEA,KAAK,CAAC;IAC5D,MAAM,IAAIC,KAAK,CAAC,sCAAsC,CAAC;EACzD;AACF;AAEA3C,GAAG,CAAC4C,MAAM,CAAC3C,IAAI,EAAE,MAAM;EACrBW,OAAO,CAACC,GAAG,CAAC,0BAA0BZ,IAAI,EAAE,CAAC;AAC/C,CAAC,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}